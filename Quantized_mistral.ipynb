{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1a994f89096144b69138cd22a7ba57a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8896ebc989b74fdc9948acf2396f2a8e",
              "IPY_MODEL_b813c937d2ed4a4d880b10170c8b012c",
              "IPY_MODEL_81a721b5e63b47fd966d94488a27d3f5"
            ],
            "layout": "IPY_MODEL_16e67cd9a09d4e5ab5a6781ad3ad4b00"
          }
        },
        "8896ebc989b74fdc9948acf2396f2a8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_16be10e4801841f98de4f0fb86dc7aaf",
            "placeholder": "​",
            "style": "IPY_MODEL_0a3990a931564e3998537887a246bf58",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "b813c937d2ed4a4d880b10170c8b012c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6b1ec445229145b1bd702367d2181cb4",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f16f2a976e94427ea773385da1e11234",
            "value": 4
          }
        },
        "81a721b5e63b47fd966d94488a27d3f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6055d982b2e54a3fb6f32527b3a3e643",
            "placeholder": "​",
            "style": "IPY_MODEL_9b33bfcc8f1c44968d1cf360d1476a5a",
            "value": " 4/4 [01:24&lt;00:00, 18.05s/it]"
          }
        },
        "16e67cd9a09d4e5ab5a6781ad3ad4b00": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "16be10e4801841f98de4f0fb86dc7aaf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a3990a931564e3998537887a246bf58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6b1ec445229145b1bd702367d2181cb4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f16f2a976e94427ea773385da1e11234": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6055d982b2e54a3fb6f32527b3a3e643": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9b33bfcc8f1c44968d1cf360d1476a5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##**Quantization of Mistral 7B**"
      ],
      "metadata": {
        "id": "RtHNa7bmzr6_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U bitsandbytes # Install bitsandbytes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rLCV51cILnKw",
        "outputId": "485a81ef-e313-4d16-d81d-61260b466399"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.10/dist-packages (0.44.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (2.5.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (1.26.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->bitsandbytes) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->bitsandbytes) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hbSXJlEvNDnS",
        "outputId": "e986e0be-d3a7-41f4-d1de-cc313cc1524b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.26.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mkzCvn1lLll6"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "import torch\n",
        "from accelerate import init_empty_weights\n",
        "from transformers import BitsAndBytesConfig"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import psutil\n",
        "\n",
        "# Function to measure memory usage (for CPU or GPU)\n",
        "def get_memory_usage():\n",
        "    # GPU Memory Usage\n",
        "    if torch.cuda.is_available():\n",
        "        return f\"{torch.cuda.memory_allocated() / (1024 ** 3):.2f} GB (GPU)\"\n",
        "    # CPU Memory Usage\n",
        "    process = psutil.Process(os.getpid())\n",
        "    return f\"{process.memory_info().rss / (1024 ** 3):.2f} GB (CPU)\""
      ],
      "metadata": {
        "id": "XEuTMU8ToPk1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_NAME = \"mistralai/Ministral-8B-Instruct-2410\"\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_use_double_quant=True,\n",
        ")"
      ],
      "metadata": {
        "id": "zH3fnQxqLt2K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Memory after loading model:\", get_memory_usage())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hh8h7nsZnWT_",
        "outputId": "8fc478d2-298c-4e87-d215-7ebd8152ed5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Memory after loading model: 0.00 GB (GPU)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "        MODEL_NAME,\n",
        "        quantization_config=bnb_config,\n",
        "        torch_dtype=torch.bfloat16,\n",
        "        device_map=\"auto\",\n",
        "        trust_remote_code=True,\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "1a994f89096144b69138cd22a7ba57a0",
            "8896ebc989b74fdc9948acf2396f2a8e",
            "b813c937d2ed4a4d880b10170c8b012c",
            "81a721b5e63b47fd966d94488a27d3f5",
            "16e67cd9a09d4e5ab5a6781ad3ad4b00",
            "16be10e4801841f98de4f0fb86dc7aaf",
            "0a3990a931564e3998537887a246bf58",
            "6b1ec445229145b1bd702367d2181cb4",
            "f16f2a976e94427ea773385da1e11234",
            "6055d982b2e54a3fb6f32527b3a3e643",
            "9b33bfcc8f1c44968d1cf360d1476a5a"
          ]
        },
        "id": "2FE7gvkEMEv3",
        "outputId": "1954c814-b028-4d2d-a30e-29f9ebc271c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1a994f89096144b69138cd22a7ba57a0"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Memory after loading model:\", get_memory_usage())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xpYuZ5R-nfEL",
        "outputId": "e343bfcc-1f7d-4555-fe4e-e3694bbb968e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Memory after loading model: 5.34 GB (GPU)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)"
      ],
      "metadata": {
        "id": "1qIK5fq3MHTQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13f7c9aa-3506-4273-9a41-4f47c1ca90fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama_fast.LlamaTokenizerFast'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565 - if you loaded a llama tokenizer from a GGUF file you can ignore this message.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline"
      ],
      "metadata": {
        "id": "1Q6OVHOUyOnf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipe = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer = tokenizer,\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    device_map=\"auto\"\n",
        ")"
      ],
      "metadata": {
        "id": "M9j7HC0rRBlC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Memory after loading model:\", get_memory_usage())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O1Ydf0mgm-3V",
        "outputId": "c7893680-500d-48e8-d821-1f8dea600639"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Memory after loading model: 5.34 GB (GPU)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "INSTRUCTION_KEY = \"### Instruction:\"\n",
        "RESPONSE_KEY = \"### Response:\"\n",
        "END_KEY = \"### End\"\n",
        "INTRO_BLURB = \"Below is an instruction that describes a task. Write a response that appropriately completes the request.\"\n",
        "PROMPT_FOR_GENERATION_FORMAT = \"\"\"{intro}\n",
        "{instruction_key}\n",
        "{instruction}\n",
        "{end_key}\n",
        "{response_key}\n",
        "\"\"\".format(\n",
        "    intro=INTRO_BLURB,\n",
        "    instruction_key=INSTRUCTION_KEY,\n",
        "    instruction=\"{instruction}\",\n",
        "    end_key=END_KEY,\n",
        "    response_key=RESPONSE_KEY,\n",
        ")"
      ],
      "metadata": {
        "id": "HS9rXCFZyomD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_stream(instruction, temperature, top_p, top_k, max_new_tokens):\n",
        "    #prompt = \"As a data scientist, can you explain the concept of regularization in machine learning?\"\n",
        "    prompt = PROMPT_FOR_GENERATION_FORMAT.format(instruction=instruction.lower())\n",
        "\n",
        "    sequences = pipe(\n",
        "        prompt,\n",
        "        do_sample=True,\n",
        "        max_new_tokens= max_new_tokens, # 100,\n",
        "        temperature=temperature, # 0.7,\n",
        "        top_k=top_k, #50,\n",
        "        top_p=top_p, #0.95,\n",
        "        num_return_sequences=1,\n",
        "    )\n",
        "    return sequences[0]['generated_text']"
      ],
      "metadata": {
        "id": "cYGbT_vyyYk0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = process_stream(instruction=\"What is the capital of India\",top_p=50,top_k=1,temperature=1,max_new_tokens=100)\n",
        "#response = generate_text(prompt_settings.instruction)\n",
        "response = response.split('### Response:')[-1]\n",
        "wrapped_text = response #textwrap.fill(response, width=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mVo2dgVqyYrs",
        "outputId": "0fe51bdb-8714-4764-f711-420307f75c41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(wrapped_text)"
      ],
      "metadata": {
        "id": "AnSxXjF0nKXl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4de832a-79ac-4bad-e16d-5237ffec896b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "The capital of India is New Delhi.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z-b5iY1JzWrN",
        "outputId": "6a9e4d1e-a14c-40ae-d253-5b22e41da81e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "The capital of India is New Delhi.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Quantization of Mistral 8B**"
      ],
      "metadata": {
        "id": "UrBoMxRqlc6U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U bitsandbytes # Install bitsandbytes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f963c1f-ee38-4657-aff8-dee412065625",
        "id": "Ccmw6zlMlc6V"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting bitsandbytes\n",
            "  Downloading bitsandbytes-0.44.1-py3-none-manylinux_2_24_x86_64.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (2.5.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (1.26.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->bitsandbytes) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->bitsandbytes) (3.0.2)\n",
            "Downloading bitsandbytes-0.44.1-py3-none-manylinux_2_24_x86_64.whl (122.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.4/122.4 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: bitsandbytes\n",
            "Successfully installed bitsandbytes-0.44.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7270b21-9181-4989-ec48-fb49623b9728",
        "id": "UntfWDxhlc6W"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.26.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3tvaUXZBlc6W"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "import torch\n",
        "from accelerate import init_empty_weights\n",
        "from transformers import BitsAndBytesConfig"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import psutil\n",
        "\n",
        "# Function to measure memory usage (for CPU or GPU)\n",
        "def get_memory_usage():\n",
        "    # GPU Memory Usage\n",
        "    if torch.cuda.is_available():\n",
        "        return f\"{torch.cuda.memory_allocated() / (1024 ** 3):.2f} GB (GPU)\"\n",
        "    # CPU Memory Usage\n",
        "    process = psutil.Process(os.getpid())\n",
        "    return f\"{process.memory_info().rss / (1024 ** 3):.2f} GB (CPU)\""
      ],
      "metadata": {
        "id": "vmK35Mbslc6X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_NAME = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_use_double_quant=True,\n",
        ")"
      ],
      "metadata": {
        "id": "NcCcDMCklc6X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Memory after loading model:\", get_memory_usage())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7898191-e8c6-4535-d8d5-459f2b70821a",
        "id": "ruqsFRz_lc6X"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Memory after loading model: 0.00 GB (GPU)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "        MODEL_NAME,\n",
        "        quantization_config=bnb_config,\n",
        "        torch_dtype=torch.bfloat16,\n",
        "        device_map=\"auto\",\n",
        "        trust_remote_code=True,\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273,
          "referenced_widgets": [
            "774d952dec944b1e9d2b26e7334b9c15",
            "b96e02633bf844b2aa89c08743deab9b",
            "793ea130a5bb470e979f5a8dac98d139",
            "7859840b7de64fcfba329d985c8645d6",
            "3313621829f846fbbbeb395f4c0e8597",
            "4d87ef44713849d69c04c4ec91306148",
            "ab95b269da3648a4aeae4cd8eb3be632",
            "c9cbe624e5fb449f8c579b99d92cffaf",
            "c4828c9ca1544432adf2a76b2914cb82",
            "4a93af2c98654e6fba7aff08ae27f119",
            "63fcdb0c7476494785850dd7663b748e",
            "d87e9de688f64aac8dc40e7d8d8e2b36",
            "80833bba3e30459793dc2035d0fcf35e",
            "bccf8b4e95ca4b2d8f116dd127828ca4",
            "840e902b06f344eb9bc4542119de8e80",
            "c98c4db281f84560b79b86c05cee0965",
            "8e497dd572f14e0da053e5bb52a706c0",
            "e4a094e7b0084c7eae9e5f8ca8bda377",
            "ca8a4dd33f8e435d8e89e79f829e0e51",
            "5b08484088de42ac8e41db770f1d7169",
            "d9bf17709758428a869f95705326fd44",
            "f66e9aea8088464cbe35e65f2c44990c",
            "a63259408ade40c4a90507831392b302",
            "6f5ec5799cbf4349a7c6bb2499ede37a",
            "98b73e7e6a014cb18e23345f6131f329",
            "5785c655711442159b6dcdd1d46c167a",
            "1055154632374ec7a95da48b50289d10",
            "b68ded1c50ff4b35884ff0131fe7761d",
            "8a805ca6f3c2436db72016a6f444f728",
            "b6151be19fd94802affa3ef5bc68a2d5",
            "02a80c73539341ac86d46999d29c9ff3",
            "61438cc82ada47279fb8bd4d9bb19f70",
            "3d97c273e8aa45bea56f918ee284092e",
            "7457b6abab5e4e6cb0ed321495e701a9",
            "b3c4e524f7ea485f9e7a84a23853fbac",
            "f81661a700a741f7b24b7579eb1cbdd3",
            "24076d8b1c5147cb91b4fe7d33d7bae7",
            "e87c3cf17edd43ffb5031e717bf0144f",
            "effa06982ea844f4970216daa626cd54",
            "0c205fa544a24fa3a5573c168a0e2ab4",
            "1da21e5a24be4b4ebb01a1d7d250e903",
            "92a88d1fad994e30aedc11ee731bffbd",
            "10a6cef1526643e99006c69f186cec8b",
            "1ad8e94a8a5d40859bb6bba62a9029ca",
            "33ce0563a9ea4bd2854e377584307568",
            "f6653397db1a4f3a84f81856d21f2abc",
            "3a325ec007ed45b0903a412b5305b235",
            "f46f7c60e97c47cb820ec788d5ef2117",
            "cad8e74e63f7461481dc488f5bc01934",
            "f33ad8d303b04fdeadd84d9259cdf02c",
            "28912656332f42ac99ffb93393ac6119",
            "c87b563d12134fed92b8eb665f1c0540",
            "75dc48b33f234ec588bda1432050fa7a",
            "1c3f83fb62af43d68016778e91b2f5bc",
            "f9b39920446e4ebfb15bf6d8b076ea0c",
            "1d021c8982524cfaaf25cd0a19bc7b8c",
            "278f3a2694854bb1b5b7a195461eee38",
            "566484f6635f4623854b45c56acba37e",
            "0d24378785224829b15a6140ee259d95",
            "1e063726567d447589eb0263cbbbc8eb",
            "eaefc34d563b4dc18a470888b8bf505c",
            "41c1c2f9c8d945db9263be2880eec0ed",
            "6cd5462a06ef435292d264cba652f6d6",
            "1f9b1c6d7a6e4009964bd0c0ad911de7",
            "a6e89aa466da446ea9059f564801a418",
            "5d7a1940d67748b29241d7eb40b71cc3",
            "bd24c295dac743d0a4719d73da48a654",
            "32e68f5163464d98a9e378ce6af6daf9",
            "e501ee2cf7934ab7a78fbbdcfd3bd0c1",
            "90c5f08466ad46d28cc8507b3a5c7ec1",
            "19cfb6675f4647bd8273a0e20105caa4",
            "0e03717061e74710a53c064b5c4c0330",
            "bf0adafa72e54844a48dff53a23a3590",
            "abc4f86b8fef4231b252c6c1a2aa60ed",
            "ade0d638b8a248d7b85f84080db672ef",
            "febf86dab9844d4385e579ef064ed0a2",
            "f1b79eed212e4648938b12be0dc4bb7f",
            "e06e75be5bc143bf9d0b746550b1bb6f",
            "6f4f9d0a4af24ece8a7056572de561b1",
            "f4b0083d16d741ee8800e2b4f7705a88",
            "77c8a921710a41c98c7baa0e2ec5b50b",
            "023f4d318a554310937b385ae8e2551c",
            "28f3d7c8e23a4ddfa415b5ea021bb578",
            "7c5be8a1bb6f4305bc3767489a88a2a2",
            "12cb954f357b4ef39be6504796f13a72",
            "7e5c42141c0e4d598592e53ee85d13ed",
            "5bd672ac76454f5098646b93d5db76cb",
            "ff37d6d307cd4e1ea07af0d7ef9c5078"
          ]
        },
        "outputId": "9cc96a4e-456f-4535-be35-5b071ec27212",
        "id": "3jbjWaF8lc6Y"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/596 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "774d952dec944b1e9d2b26e7334b9c15"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors.index.json:   0%|          | 0.00/25.1k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d87e9de688f64aac8dc40e7d8d8e2b36"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a63259408ade40c4a90507831392b302"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00001-of-00003.safetensors:   0%|          | 0.00/4.94G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7457b6abab5e4e6cb0ed321495e701a9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00002-of-00003.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "33ce0563a9ea4bd2854e377584307568"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00003-of-00003.safetensors:   0%|          | 0.00/4.54G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1d021c8982524cfaaf25cd0a19bc7b8c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bd24c295dac743d0a4719d73da48a654"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/111 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e06e75be5bc143bf9d0b746550b1bb6f"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Memory after loading model:\", get_memory_usage())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb40131a-40bd-40f3-df86-2ae7595caf1e",
        "id": "G1hFL_u8lc6Y"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Memory after loading model: 3.84 GB (GPU)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200,
          "referenced_widgets": [
            "bab3c0cef3af4e6eac41c5b110697d98",
            "24a13c5d75454b7fa8a5f382596c41e0",
            "435767c142324707814207dd4950d54d",
            "3061f417e40e424a84e42252307b5e9e",
            "c1cd36e9f140423eb7fb31af241ee7e3",
            "61099025ab4e4767a57c40c4ecc243cc",
            "dc6a5e02a5ff49f0bf877dcab880b542",
            "a3ed170dea464953bfdab7890f41b40a",
            "c7bb36251aad4db3981ae6e17426e656",
            "d8a02a6871ab4b89a706d47599fd0aec",
            "228d3521405b40d6b2275fa4c8a8ad49",
            "4b493dd0c4ad4d92a5e91e2584478ce0",
            "9b8da638defe40ba865ca1899c4eef72",
            "34d13392d9ba44459ba6598b858493a6",
            "5b0fa53a8ed243f8b1c28fa4e2287f14",
            "ad288297ed194139a8dc9a4b79814f2d",
            "6d2bd26ab913444099f6792bd7e1a7b5",
            "6c39328460c540c69c9ff746943267ad",
            "6a160bdcf8bf4f729fdc8597ecd1987e",
            "ccaabbfd204f429fa39b307b7882a660",
            "af15d44499a9427d93c85210786189ee",
            "1f10a38564854d0cba5db7e2e24c5bd4",
            "a73fa66714ac498c88ad6e4f155d4ccb",
            "d60a94bd2b52414182b9fee1bcf2e08b",
            "b2b72fc0bcd34bc99820fb0a1a71ea11",
            "b614aab1392444e0beaaede3cf1ed15e",
            "e655f823bcf84a6fac1cc27542209c36",
            "c7f7515f3acb4c899e9deac265965bc7",
            "aca99b4d277846efaf774b318e06f319",
            "f5b2f791b5824e6d981da1ac2f9e1f64",
            "d3ec48cca3fd4c0d8ccb2bb8283b7068",
            "a9f17f70e3f24f1b83020d474b310766",
            "f0f41440b5c049ca886e859b4e9b80e5",
            "fbd96332aa1b466cbad29ee5b6f1c0f4",
            "3f2e1c8116844fcc8cd08b7a6989397c",
            "044fa7274c1d4791a764c5edd18336d1",
            "32d3ce6a838140979b40766a8847f717",
            "31d7e11f78bb4e31bd26eecc0377a81f",
            "eb18f21726c448b481eceb792c257326",
            "0a37d1b25f6044e5b7cded16896ddf7a",
            "ac5df3863e334ea68e6876113d09e18a",
            "3a9a7d3f8407404d8036a65e65c40447",
            "181d457b237a4b3591cccd5eedd6106a",
            "4f0c046cd84c4466b477eef4d76eeaa7"
          ]
        },
        "outputId": "0919fecc-6d2f-4c7f-ca0d-50b0d6a49081",
        "id": "4-6wpuPWlc6Z"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/models/auto/tokenization_auto.py:809: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/2.10k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bab3c0cef3af4e6eac41c5b110697d98"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4b493dd0c4ad4d92a5e91e2584478ce0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.80M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a73fa66714ac498c88ad6e4f155d4ccb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fbd96332aa1b466cbad29ee5b6f1c0f4"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline"
      ],
      "metadata": {
        "id": "HcKcTtvrlc6Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipe = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer = tokenizer,\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    device_map=\"auto\"\n",
        ")"
      ],
      "metadata": {
        "id": "TaWJp6wPlc6a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Memory after loading model:\", get_memory_usage())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c104c929-598f-4710-e655-bee2903a475b",
        "id": "NRbAXIbdlc6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Memory after loading model: 3.85 GB (GPU)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "INSTRUCTION_KEY = \"### Instruction:\"\n",
        "RESPONSE_KEY = \"### Response:\"\n",
        "END_KEY = \"### End\"\n",
        "INTRO_BLURB = \"Below is an instruction that describes a task. Write a response that appropriately completes the request.\"\n",
        "PROMPT_FOR_GENERATION_FORMAT = \"\"\"{intro}\n",
        "{instruction_key}\n",
        "{instruction}\n",
        "{end_key}\n",
        "{response_key}\n",
        "\"\"\".format(\n",
        "    intro=INTRO_BLURB,\n",
        "    instruction_key=INSTRUCTION_KEY,\n",
        "    instruction=\"{instruction}\",\n",
        "    end_key=END_KEY,\n",
        "    response_key=RESPONSE_KEY,\n",
        ")"
      ],
      "metadata": {
        "id": "3IwOjr8plc6a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_stream(instruction, temperature, top_p, top_k, max_new_tokens):\n",
        "    #prompt = \"As a data scientist, can you explain the concept of regularization in machine learning?\"\n",
        "    prompt = PROMPT_FOR_GENERATION_FORMAT.format(instruction=instruction.lower())\n",
        "\n",
        "    sequences = pipe(\n",
        "        prompt,\n",
        "        do_sample=True,\n",
        "        max_new_tokens= max_new_tokens, # 100,\n",
        "        temperature=temperature, # 0.7,\n",
        "        top_k=top_k, #50,\n",
        "        top_p=top_p, #0.95,\n",
        "        num_return_sequences=1,\n",
        "    )\n",
        "    return sequences[0]['generated_text']"
      ],
      "metadata": {
        "id": "RAaPpxY8lc6b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = process_stream(instruction=\"What is the capital of India\",top_p=50,top_k=1,temperature=1,max_new_tokens=100)\n",
        "#response = generate_text(prompt_settings.instruction)\n",
        "response = response.split('### Response:')[-1]\n",
        "wrapped_text = response #textwrap.fill(response, width=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d56fcd43-81c8-4cd6-f0bf-aff36af8c645",
        "id": "yULh43calc6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(wrapped_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8dc0ada4-4c05-48ca-aa2b-5643945c8cc6",
        "id": "ugwPHXt1lc6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "The capital city of India is New Delhi. It is a city that holds great historical significance and is home to several iconic landmarks such as the Red Fort, Qutub Minar, and India Gate. New Delhi serves as the political and administrative hub of the country.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00d0c1d7-9a81-4f41-ea7f-b218027bd83f",
        "id": "Zx_aar6dlc6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "The capital city of India is New Delhi. It is a city that holds great historical significance and is home to several iconic landmarks such as the Red Fort, Qutub Minar, and India Gate. New Delhi serves as the political and administrative hub of the country.\n"
          ]
        }
      ]
    }
  ]
}